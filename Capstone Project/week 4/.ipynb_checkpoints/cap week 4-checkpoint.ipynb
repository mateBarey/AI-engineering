{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n",
    "You will take several screenshots of your work and share your notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
    " </div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "!unzip -q Negative_tensors.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will install torchvision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1ef80e0fb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/home/dsxuser/work\"\n",
    "        positive=\"Positive_tensors\"\n",
    "        negative='Negative_tensors'\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "                  \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train=True)\n",
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/dsxuser/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c84e814d9a4c19be89eb597a4a42fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "    \n",
    "\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc=nn.Linear(512,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you will train your, model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "# Type your code here\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=100)\n",
    "validation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=1\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "correct=0\n",
    "N_test=len(validation_dataset)\n",
    "N_train=len(train_dataset)\n",
    "start_time = time.time()\n",
    "miscalc_list = []\n",
    "#n_epochs\n",
    "\n",
    "Loss=0\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        model.train() \n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model(x)\n",
    "        # calculate loss \n",
    "        loss = criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.data)\n",
    "    correct=0\n",
    "    for i,(x_test, y_test) in enumerate(validation_loader):\n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "        #make a prediction \n",
    "        z=model(x_test)\n",
    "        #find max \n",
    "        _, yhat=torch.max(z.data,1)\n",
    "        #Calculate misclassified  samples in mini-batch \n",
    "        correct += (yhat==y_test).sum().item()\n",
    "        #hint +=(yhat==y_test).sum().item()\n",
    "        if yhat[i] != y_test[i]:\n",
    "            miscalc_list.append(i)\n",
    "            \n",
    "    \n",
    "       \n",
    "    accuracy=correct/N_test\n",
    "    accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9945 9945.0\n"
     ]
    }
   ],
   "source": [
    "accuracy\n",
    "correct = accuracy*N_test\n",
    "print(accuracy,correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "missclassified_samples_list = []\n",
    "for i,(x_test,y_test) in enumerate(validation_loader):\n",
    "    z = model(x_test)\n",
    "    _,yhat = torch.max(z.data,1)\n",
    "    if yhat[i] != y_test[i]:\n",
    "        missclassified_samples_list.append(i)\n",
    "\n",
    "missclassified_samples_list[0::3]\n",
    "'''\n",
    "miscalc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html\"> CLICK HERE </a> Click here to see how to share your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
